{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173528c-3385-4655-a9e6-8bd90afb7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85755dd7-0534-48bf-a33d-1b04f2c8512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AutoModel from huggingface model repository\n",
    "# modelName = \"sentence-transformers/all-MiniLM-L6-v2\";\n",
    "modelName = \"neuml/pubmedbert-base-embeddings\";\n",
    "pubmedbert_tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "pubmedbert_model = AutoModel.from_pretrained(modelName)\n",
    "\n",
    "modelName = \"microsoft/biogpt\";\n",
    "biogpt_tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "biogpt_model = AutoModel.from_pretrained(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1d6f30b-9b1a-46ca-92ae-fb0c1a67a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BioGptModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def embeddings(model, tokenizer, sentences):\n",
    "    # # Tokenize sentences\n",
    "    encoded_input = tokenizer(\n",
    "        sentences, padding=True, truncation=True, max_length=128, return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # # Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "    return sentence_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d529584c-a141-4b59-82b7-4a1def41e338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5246,  0.1851,  1.5204,  ...,  0.0856,  0.0222,  0.9674],\n",
      "        [ 0.0245, -1.2456,  0.5576,  ..., -0.6955,  1.2123,  0.1388],\n",
      "        [-0.7520,  0.5984,  0.2248,  ..., -0.1149,  0.9079,  0.3904]])\n",
      "tensor([[-0.6495,  0.5809, -0.4687,  ..., -0.1336, -0.7726, -0.2508],\n",
      "        [-0.9131,  0.6357,  0.5418,  ..., -0.2846, -0.9001,  0.1210],\n",
      "        [-0.5454,  0.9630, -0.4064,  ...,  0.1175, -1.1538, -0.1450]])\n"
     ]
    }
   ],
   "source": [
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\n",
    "    \"This framework generates embeddings for each input sentence\",\n",
    "    \"Sentences are passed as a list of string.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "]\n",
    "\n",
    "biogpt_embeddings = embeddings(biogpt_model, biogpt_tokenizer, sentences)\n",
    "pubmedbert_embeddings = embeddings(pubmedbert_model, pubmedbert_tokenizer, sentences)\n",
    "print(biogpt_embeddings)\n",
    "print(pubmedbert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841e887-405b-4074-8b6a-cacfc22cbc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
